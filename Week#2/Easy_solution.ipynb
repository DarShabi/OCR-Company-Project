{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarShabi/OCR-Company-Project/blob/main/Week%232/Easy_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "65pQX7d_nJHn"
      },
      "outputs": [],
      "source": [
        "!pip install -q ImageHash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_bCflWLnPED",
        "outputId": "0dbe7ba1-b537-4844-d5b8-5c14f6131a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "!apt-get install tesseract-ocr\n",
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrbEIA7s6MF3",
        "outputId": "99f0bbed-14e9-4964-9b65-020d0b54ff44"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.11.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pyJ7tuD3nQm-"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from PIL import ImageEnhance, ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "from collections import Counter, defaultdict\n",
        "import re\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import imagehash\n",
        "import pytesseract\n",
        "import fasttext\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import re\n",
        "import urllib.request\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asse6VnvnTZN",
        "outputId": "1620f4d6-3a9a-4b64-c4e0-739da7f13647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "66p_E9aEnU0R"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/OCR_Project/data.csv'\n",
        "\n",
        "df = pd.read_csv(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MOttIL2Sngkx"
      },
      "outputs": [],
      "source": [
        "NA_df = pd.read_csv('/content/drive/MyDrive/OCR_Project/N_A_images.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PreProcess - changing NaN to string 'unknown'"
      ],
      "metadata": {
        "id": "62qJcpqMDLMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nan_count_before = df['text'].isnull().sum()\n",
        "print(f\"Number of NaN values before replacement: {nan_count_before}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzRg6leSDLUz",
        "outputId": "2a28424c-0129-468e-da02-f16f9463a021"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of NaN values before replacement: 1031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'NaN' with 'unknown'\n",
        "df['text'].fillna('unknown', inplace=True)"
      ],
      "metadata": {
        "id": "h09XRN-UDMGa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the count of 'NaN' after replacement\n",
        "nan_count_after = df['text'].isnull().sum()\n",
        "print(f\"Number of NaN values after replacement: {nan_count_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr3XB0CSDMJa",
        "outputId": "09f63327-3071-4ba2-87bc-3f75c059a8de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of NaN values after replacement: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyYprwi1n27K",
        "outputId": "c25c1fc1-ab5c-4fc8-b6f4-55116bce62d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 3407\n",
            "Validation size: 487\n",
            "Test size: 974\n"
          ]
        }
      ],
      "source": [
        "# Initial split: 80% train, 20% temp\n",
        "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "\n",
        "# Split the 20% temp into half: 10% validation, 10% test\n",
        "val_df, test_df = train_test_split(temp_df, test_size=2/3, random_state=42)\n",
        "\n",
        "print(f\"Train size: {len(train_df)}\")\n",
        "print(f\"Validation size: {len(val_df)}\")\n",
        "print(f\"Test size: {len(test_df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjTxaO66o2zB"
      },
      "source": [
        "# Step 1: Solving N/A and one-pixle images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Calculate hashes for all images in na_df and store their respective texts\n",
        "hashes_na = {}\n",
        "for index, row in NA_df.iterrows():\n",
        "    image_path = row['file_path']\n",
        "    with Image.open(image_path) as img:\n",
        "        h = imagehash.dhash(img)\n",
        "        hashes_na[h] = row['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3HG1sOt07Z3",
        "outputId": "1597a32b-f175-4f8b-cf36-876a059b8d44"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "is4IaZ73qZfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720857f3-c882-46c2-8956-f58c0224e393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 2 & 3. Calculate hashes for all images in val_df and assign matching predicted_text\n",
        "for index, row in val_df.iterrows():\n",
        "    image_path = row['file_path']\n",
        "    with Image.open(image_path) as img:\n",
        "        h = imagehash.dhash(img)\n",
        "        if h in hashes_na:\n",
        "            val_df.at[index, 'predicted_text'] = hashes_na[h]\n",
        "        else:\n",
        "            val_df.at[index, 'predicted_text'] = 'TBD'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = (val_df['predicted_text'] == val_df['text']).sum()\n",
        "total_predictions = len(val_df)\n",
        "accuracy = (correct_predictions / total_predictions) * 100\n",
        "print(f\"Accuracy after accounting for visually similar images: {accuracy:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ7exAqT1C9Z",
        "outputId": "1f2139d9-0a9b-41ef-db3a-200d6d090c98"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after accounting for visually similar images: 6.1602%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OO1c8PCbrfkB"
      },
      "outputs": [],
      "source": [
        "def find_one_color_images(df, column_name='file_path'):\n",
        "    \"\"\"\n",
        "    Identifies images in the given DataFrame that consist of a single color.\n",
        "\n",
        "    Parameters:\n",
        "    df (DataFrame): A DataFrame containing file paths to the images.\n",
        "    column_name (str, optional): The name of the column in the DataFrame containing the file paths. Defaults to 'file_path'.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of file paths to the images that consist of a single color.\n",
        "    \"\"\"\n",
        "    one_color_images = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        image_path = row[column_name]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        pixels = np.array(image)\n",
        "        first_pixel = pixels[0, 0]\n",
        "\n",
        "        if (pixels == first_pixel).all():\n",
        "            one_color_images.append(image_path)\n",
        "\n",
        "    return one_color_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OnKfGIAIqtD0"
      },
      "outputs": [],
      "source": [
        "def set_nan_for_one_color_images(df, one_color_images):\n",
        "    \"\"\"\n",
        "    Set the prediction to NaN for one-color images.\n",
        "\n",
        "    Parameters:\n",
        "    df (DataFrame): The DataFrame containing the image paths and their predictions.\n",
        "    one_color_images (list): The list of image paths that are one-color images.\n",
        "\n",
        "    Returns:\n",
        "    DataFrame: Updated DataFrame with predictions set to NaN for one-color images.\n",
        "    \"\"\"\n",
        "    for img_path in one_color_images:\n",
        "        df.loc[df['file_path'] == img_path, 'predicted_text'] = 'unknown'\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gC0G25qkraCG"
      },
      "outputs": [],
      "source": [
        "# Identify one-color images in the val_df\n",
        "one_color_images_val = find_one_color_images(val_df)\n",
        "\n",
        "# Update the val_df to set predictions to NaN for the identified one-color images\n",
        "val_df = set_nan_for_one_color_images(val_df, one_color_images_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fSnpN-Y3sETs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab0eeb2-7bb4-4998-98c0-87bfbb25fb59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after handling 'n_a_images' and one-color images: 6.9815%\n"
          ]
        }
      ],
      "source": [
        "correct_predictions = ((val_df['predicted_text'] == val_df['text'])).sum()\n",
        "\n",
        "total_predictions = len(val_df)\n",
        "\n",
        "accuracy = (correct_predictions / total_predictions) * 100\n",
        "\n",
        "print(f\"Accuracy after handling 'n_a_images' and one-color images: {accuracy:.4f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Solving no text images."
      ],
      "metadata": {
        "id": "ISdMUk4D5q2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\"\n",
        "filename = \"lid.176.bin\"\n",
        "\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "print(f\"{filename} has been downloaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPz-lSlL7JHG",
        "outputId": "557abf9a-3897-4141-a85c-fa08d7a2447a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lid.176.bin has been downloaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pretrained FastText model for language detection\n",
        "lang_model = fasttext.load_model('lid.176.bin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js31J70s6HK3",
        "outputId": "9d6d13b7-f984-4c83-fc34-da38b07a1b6e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "\n",
        "def enhanced_ocr(image_path):\n",
        "    \"\"\"\n",
        "    Pre-process and recognize text from an image using Tesseract with enhanced configurations.\n",
        "\n",
        "    Parameters:\n",
        "    image_path (str): Path to the image file.\n",
        "\n",
        "    Returns:\n",
        "    str: Recognized text from the image.\n",
        "    \"\"\"\n",
        "    global counter\n",
        "    counter += 1\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Pre-processing\n",
        "    img = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n",
        "    img = ImageOps.autocontrast(img)           # Improve contrast\n",
        "    enhancer = ImageEnhance.Sharpness(img)\n",
        "    img = enhancer.enhance(2)                  # Sharpen the image\n",
        "\n",
        "    # Possible rotations\n",
        "    rotations = [0, 90, 180, 270]\n",
        "    best_text = ''\n",
        "    best_angle = 0\n",
        "\n",
        "    # Try OCR on different rotations and choose the one with the maximum length output\n",
        "    for angle in rotations:\n",
        "        rotated_img = img.rotate(angle)\n",
        "        text = pytesseract.image_to_string(rotated_img, config='--psm 11')\n",
        "        if len(text) > len(best_text):\n",
        "            best_text = text\n",
        "            best_angle = angle\n",
        "\n",
        "    # Check if there's no or very short text\n",
        "    if len(best_text) < 2:\n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f\"Processed {counter} images. Current image took: {elapsed_time:.2f} seconds. Result: unknown\")\n",
        "        return 'unknown'\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"Processed {counter} images. Current image took: {elapsed_time:.2f} seconds. Result length: {len(best_text)}\")\n",
        "    return 'TBD'"
      ],
      "metadata": {
        "id": "-9AiaGBq6ZcX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.loc[val_df['predicted_text'] == 'TBD', 'predicted_text'] = val_df[val_df['predicted_text'] == 'TBD']['file_path'].apply(enhanced_ocr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tb9Fo3Zs6ast",
        "outputId": "e5038f6d-c883-40e7-bf32-918c779db4cd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1 images. Current image took: 0.53 seconds. Result: unknown\n",
            "Processed 2 images. Current image took: 4.84 seconds. Result length: 490\n",
            "Processed 3 images. Current image took: 6.46 seconds. Result length: 281\n",
            "Processed 4 images. Current image took: 3.24 seconds. Result length: 233\n",
            "Processed 5 images. Current image took: 17.18 seconds. Result length: 1466\n",
            "Processed 6 images. Current image took: 2.74 seconds. Result length: 266\n",
            "Processed 7 images. Current image took: 0.89 seconds. Result: unknown\n",
            "Processed 8 images. Current image took: 3.46 seconds. Result length: 85\n",
            "Processed 9 images. Current image took: 0.95 seconds. Result length: 23\n",
            "Processed 10 images. Current image took: 3.46 seconds. Result length: 211\n",
            "Processed 11 images. Current image took: 3.76 seconds. Result length: 295\n",
            "Processed 12 images. Current image took: 1.09 seconds. Result length: 37\n",
            "Processed 13 images. Current image took: 7.64 seconds. Result length: 435\n",
            "Processed 14 images. Current image took: 2.79 seconds. Result length: 152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15 images. Current image took: 0.56 seconds. Result length: 5\n",
            "Processed 16 images. Current image took: 14.03 seconds. Result length: 914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17 images. Current image took: 0.51 seconds. Result: unknown\n",
            "Processed 18 images. Current image took: 6.91 seconds. Result length: 365\n",
            "Processed 19 images. Current image took: 2.40 seconds. Result length: 93\n",
            "Processed 20 images. Current image took: 15.25 seconds. Result length: 718\n",
            "Processed 21 images. Current image took: 0.83 seconds. Result length: 51\n",
            "Processed 22 images. Current image took: 6.26 seconds. Result length: 568\n",
            "Processed 23 images. Current image took: 1.37 seconds. Result length: 36\n",
            "Processed 24 images. Current image took: 18.15 seconds. Result length: 1374\n",
            "Processed 25 images. Current image took: 0.57 seconds. Result length: 12\n",
            "Processed 26 images. Current image took: 0.50 seconds. Result: unknown\n",
            "Processed 27 images. Current image took: 11.49 seconds. Result length: 1123\n",
            "Processed 28 images. Current image took: 7.44 seconds. Result length: 599\n",
            "Processed 29 images. Current image took: 6.48 seconds. Result length: 326\n",
            "Processed 30 images. Current image took: 2.46 seconds. Result length: 146\n",
            "Processed 31 images. Current image took: 0.66 seconds. Result length: 16\n",
            "Processed 32 images. Current image took: 7.35 seconds. Result length: 789\n",
            "Processed 33 images. Current image took: 3.73 seconds. Result length: 238\n",
            "Processed 34 images. Current image took: 7.51 seconds. Result length: 320\n",
            "Processed 35 images. Current image took: 0.73 seconds. Result length: 60\n",
            "Processed 36 images. Current image took: 3.37 seconds. Result length: 237\n",
            "Processed 37 images. Current image took: 2.54 seconds. Result length: 150\n",
            "Processed 38 images. Current image took: 4.01 seconds. Result length: 382\n",
            "Processed 39 images. Current image took: 2.89 seconds. Result length: 398\n",
            "Processed 40 images. Current image took: 2.41 seconds. Result length: 148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 41 images. Current image took: 0.89 seconds. Result: unknown\n",
            "Processed 42 images. Current image took: 2.00 seconds. Result length: 102\n",
            "Processed 43 images. Current image took: 2.74 seconds. Result length: 201\n",
            "Processed 44 images. Current image took: 1.64 seconds. Result length: 49\n",
            "Processed 45 images. Current image took: 2.68 seconds. Result length: 111\n",
            "Processed 46 images. Current image took: 10.63 seconds. Result length: 364\n",
            "Processed 47 images. Current image took: 9.66 seconds. Result length: 645\n",
            "Processed 48 images. Current image took: 2.22 seconds. Result length: 75\n",
            "Processed 49 images. Current image took: 1.38 seconds. Result length: 91\n",
            "Processed 50 images. Current image took: 10.53 seconds. Result length: 558\n",
            "Processed 51 images. Current image took: 1.41 seconds. Result length: 47\n",
            "Processed 52 images. Current image took: 2.26 seconds. Result length: 149\n",
            "Processed 53 images. Current image took: 1.59 seconds. Result length: 131\n",
            "Processed 54 images. Current image took: 2.66 seconds. Result length: 114\n",
            "Processed 55 images. Current image took: 2.85 seconds. Result length: 97\n",
            "Processed 56 images. Current image took: 6.75 seconds. Result length: 598\n",
            "Processed 57 images. Current image took: 3.93 seconds. Result length: 47\n",
            "Processed 58 images. Current image took: 1.79 seconds. Result length: 67\n",
            "Processed 59 images. Current image took: 7.32 seconds. Result length: 314\n",
            "Processed 60 images. Current image took: 1.49 seconds. Result length: 82\n",
            "Processed 61 images. Current image took: 5.30 seconds. Result length: 297\n",
            "Processed 62 images. Current image took: 7.61 seconds. Result length: 92\n",
            "Processed 63 images. Current image took: 2.69 seconds. Result length: 48\n",
            "Processed 64 images. Current image took: 0.59 seconds. Result: unknown\n",
            "Processed 65 images. Current image took: 2.34 seconds. Result length: 107\n",
            "Processed 66 images. Current image took: 4.90 seconds. Result length: 291\n",
            "Processed 67 images. Current image took: 2.89 seconds. Result length: 148\n",
            "Processed 68 images. Current image took: 1.57 seconds. Result length: 47\n",
            "Processed 69 images. Current image took: 33.38 seconds. Result length: 1936\n",
            "Processed 70 images. Current image took: 10.01 seconds. Result length: 748\n",
            "Processed 71 images. Current image took: 1.15 seconds. Result length: 69\n",
            "Processed 72 images. Current image took: 1.19 seconds. Result length: 68\n",
            "Processed 73 images. Current image took: 13.39 seconds. Result length: 1184\n",
            "Processed 74 images. Current image took: 2.42 seconds. Result length: 91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 75 images. Current image took: 0.57 seconds. Result length: 5\n",
            "Processed 76 images. Current image took: 1.79 seconds. Result length: 116\n",
            "Processed 77 images. Current image took: 4.42 seconds. Result length: 455\n",
            "Processed 78 images. Current image took: 0.74 seconds. Result length: 17\n",
            "Processed 79 images. Current image took: 0.53 seconds. Result: unknown\n",
            "Processed 80 images. Current image took: 4.20 seconds. Result length: 767\n",
            "Processed 81 images. Current image took: 0.54 seconds. Result length: 4\n",
            "Processed 82 images. Current image took: 0.89 seconds. Result length: 6\n",
            "Processed 83 images. Current image took: 4.42 seconds. Result length: 516\n",
            "Processed 84 images. Current image took: 3.07 seconds. Result length: 265\n",
            "Processed 85 images. Current image took: 13.77 seconds. Result length: 1360\n",
            "Processed 86 images. Current image took: 1.25 seconds. Result length: 95\n",
            "Processed 87 images. Current image took: 1.07 seconds. Result length: 98\n",
            "Processed 88 images. Current image took: 10.23 seconds. Result length: 1331\n",
            "Processed 89 images. Current image took: 2.61 seconds. Result length: 218\n",
            "Processed 90 images. Current image took: 0.72 seconds. Result length: 24\n",
            "Processed 91 images. Current image took: 12.97 seconds. Result length: 926\n",
            "Processed 92 images. Current image took: 0.64 seconds. Result length: 15\n",
            "Processed 93 images. Current image took: 0.50 seconds. Result: unknown\n",
            "Processed 94 images. Current image took: 2.13 seconds. Result length: 131\n",
            "Processed 95 images. Current image took: 0.51 seconds. Result: unknown\n",
            "Processed 96 images. Current image took: 0.52 seconds. Result: unknown\n",
            "Processed 97 images. Current image took: 1.15 seconds. Result length: 52\n",
            "Processed 98 images. Current image took: 1.87 seconds. Result length: 126\n",
            "Processed 99 images. Current image took: 1.44 seconds. Result length: 58\n",
            "Processed 100 images. Current image took: 2.82 seconds. Result length: 79\n",
            "Processed 101 images. Current image took: 1.81 seconds. Result length: 41\n",
            "Processed 102 images. Current image took: 15.11 seconds. Result length: 767\n",
            "Processed 103 images. Current image took: 12.09 seconds. Result length: 572\n",
            "Processed 104 images. Current image took: 6.67 seconds. Result length: 506\n",
            "Processed 105 images. Current image took: 1.40 seconds. Result length: 56\n",
            "Processed 106 images. Current image took: 4.07 seconds. Result length: 213\n",
            "Processed 107 images. Current image took: 4.26 seconds. Result length: 416\n",
            "Processed 108 images. Current image took: 1.83 seconds. Result length: 80\n",
            "Processed 109 images. Current image took: 3.44 seconds. Result length: 223\n",
            "Processed 110 images. Current image took: 7.62 seconds. Result length: 435\n",
            "Processed 111 images. Current image took: 0.50 seconds. Result: unknown\n",
            "Processed 112 images. Current image took: 8.96 seconds. Result length: 844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 113 images. Current image took: 0.91 seconds. Result: unknown\n",
            "Processed 114 images. Current image took: 2.20 seconds. Result length: 99\n",
            "Processed 115 images. Current image took: 7.82 seconds. Result length: 1112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 116 images. Current image took: 0.60 seconds. Result length: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 117 images. Current image took: 0.90 seconds. Result length: 16\n",
            "Processed 118 images. Current image took: 4.35 seconds. Result length: 170\n",
            "Processed 119 images. Current image took: 5.87 seconds. Result length: 535\n",
            "Processed 120 images. Current image took: 2.96 seconds. Result length: 156\n",
            "Processed 121 images. Current image took: 1.03 seconds. Result length: 3\n",
            "Processed 122 images. Current image took: 5.30 seconds. Result length: 537\n",
            "Processed 123 images. Current image took: 0.72 seconds. Result length: 4\n",
            "Processed 124 images. Current image took: 1.18 seconds. Result length: 23\n",
            "Processed 125 images. Current image took: 1.35 seconds. Result length: 85\n",
            "Processed 126 images. Current image took: 0.60 seconds. Result length: 9\n",
            "Processed 127 images. Current image took: 1.89 seconds. Result length: 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 128 images. Current image took: 0.55 seconds. Result length: 3\n",
            "Processed 129 images. Current image took: 2.31 seconds. Result length: 88\n",
            "Processed 130 images. Current image took: 9.06 seconds. Result length: 458\n",
            "Processed 131 images. Current image took: 0.67 seconds. Result length: 7\n",
            "Processed 132 images. Current image took: 0.70 seconds. Result length: 23\n",
            "Processed 133 images. Current image took: 1.93 seconds. Result length: 91\n",
            "Processed 134 images. Current image took: 0.81 seconds. Result length: 58\n",
            "Processed 135 images. Current image took: 0.78 seconds. Result length: 29\n",
            "Processed 136 images. Current image took: 12.74 seconds. Result length: 1314\n",
            "Processed 137 images. Current image took: 0.82 seconds. Result length: 19\n",
            "Processed 138 images. Current image took: 5.12 seconds. Result length: 397\n",
            "Processed 139 images. Current image took: 2.98 seconds. Result length: 174\n",
            "Processed 140 images. Current image took: 2.87 seconds. Result length: 130\n",
            "Processed 141 images. Current image took: 3.36 seconds. Result length: 394\n",
            "Processed 142 images. Current image took: 4.92 seconds. Result length: 209\n",
            "Processed 143 images. Current image took: 1.52 seconds. Result length: 39\n",
            "Processed 144 images. Current image took: 3.83 seconds. Result length: 262\n",
            "Processed 145 images. Current image took: 2.93 seconds. Result length: 199\n",
            "Processed 146 images. Current image took: 4.69 seconds. Result length: 300\n",
            "Processed 147 images. Current image took: 1.17 seconds. Result length: 14\n",
            "Processed 148 images. Current image took: 4.04 seconds. Result length: 458\n",
            "Processed 149 images. Current image took: 1.01 seconds. Result length: 49\n",
            "Processed 150 images. Current image took: 1.23 seconds. Result length: 22\n",
            "Processed 151 images. Current image took: 0.64 seconds. Result length: 23\n",
            "Processed 152 images. Current image took: 1.93 seconds. Result length: 137\n",
            "Processed 153 images. Current image took: 9.30 seconds. Result length: 326\n",
            "Processed 154 images. Current image took: 7.92 seconds. Result length: 158\n",
            "Processed 155 images. Current image took: 0.88 seconds. Result: unknown\n",
            "Processed 156 images. Current image took: 0.90 seconds. Result: unknown\n",
            "Processed 157 images. Current image took: 1.06 seconds. Result length: 6\n",
            "Processed 158 images. Current image took: 1.44 seconds. Result length: 73\n",
            "Processed 159 images. Current image took: 5.62 seconds. Result length: 534\n",
            "Processed 160 images. Current image took: 0.86 seconds. Result length: 16\n",
            "Processed 161 images. Current image took: 0.82 seconds. Result length: 24\n",
            "Processed 162 images. Current image took: 4.23 seconds. Result length: 124\n",
            "Processed 163 images. Current image took: 3.42 seconds. Result length: 150\n",
            "Processed 164 images. Current image took: 2.81 seconds. Result length: 131\n",
            "Processed 165 images. Current image took: 4.38 seconds. Result length: 417\n",
            "Processed 166 images. Current image took: 1.30 seconds. Result length: 28\n",
            "Processed 167 images. Current image took: 1.63 seconds. Result length: 44\n",
            "Processed 168 images. Current image took: 0.96 seconds. Result length: 4\n",
            "Processed 169 images. Current image took: 2.66 seconds. Result length: 238\n",
            "Processed 170 images. Current image took: 0.52 seconds. Result: unknown\n",
            "Processed 171 images. Current image took: 1.57 seconds. Result length: 73\n",
            "Processed 172 images. Current image took: 1.09 seconds. Result length: 29\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-782926605382>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'TBD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predicted_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'TBD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menhanced_ocr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-46443b35c4fb>\u001b[0m in \u001b[0;36menhanced_ocr\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mangle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrotations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mrotated_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotated_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--psm 11'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mbest_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     return {\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     }[output_type]()\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    286\u001b[0m         }\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mrun_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{kwargs['output_filename_base']}{extsep}{extension}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTesseractNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtimeout_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTesseractError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mtimeout_manager\u001b[0;34m(proc, seconds)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2019\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = ((val_df['predicted_text'] == val_df['text'])).sum()\n",
        "\n",
        "total_predictions = len(val_df)\n",
        "\n",
        "accuracy = (correct_predictions / total_predictions) * 100\n",
        "\n",
        "print(f\"Accuracy after handling 'n_a_images', one-color images, and no-text images: {accuracy:.4f}%\")\n"
      ],
      "metadata": {
        "id": "Fg3xx0to_MHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rows where 'text' is 'unknown' but 'predicted_text' is not\n",
        "unknown_text_diff_predicted_val = val_df[(val_df['text'] == 'unknown') & (val_df['predicted_text'] != 'unknown')]\n",
        "\n",
        "# Rows where 'predicted_text' is 'unknown' but 'text' is not\n",
        "unknown_predicted_diff_text_val = val_df[(val_df['predicted_text'] == 'unknown') & (val_df['text'] != 'unknown')]\n",
        "\n",
        "# Calculate percentages\n",
        "percentage_unknown_text_diff_predicted_val = (len(unknown_text_diff_predicted_val) / len(val_df)) * 100\n",
        "percentage_unknown_predicted_diff_text_val = (len(unknown_predicted_diff_text_val) / len(val_df)) * 100\n",
        "\n",
        "print(f\"Percentage where 'text' in val_df is 'unknown' but 'predicted_text' is not: {percentage_unknown_text_diff_predicted_val:.2f}%\")\n",
        "print(f\"Percentage where 'predicted_text' in val_df is 'unknown' but 'text' is not: {percentage_unknown_predicted_diff_text_val:.2f}%\")\n"
      ],
      "metadata": {
        "id": "bK2xUbEVDH0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images_from_df(dataframe, num_images=5):\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "    for idx, (ax, row) in enumerate(zip(axes, dataframe.iterrows())):\n",
        "        image_path = row[1]['file_path']\n",
        "        image = Image.open(image_path)\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(f\"Text: {row[1]['text']}\\nPredicted: {row[1]['predicted_text']}\")\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "PTOwPWFcLFmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_images_from_df(unknown_text_diff_predicted_val)\n",
        "display_images_from_df(unknown_predicted_diff_text_val)"
      ],
      "metadata": {
        "id": "HLkLE3yWLIek"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcmivCZbf5RL3yfbNO8WKz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}